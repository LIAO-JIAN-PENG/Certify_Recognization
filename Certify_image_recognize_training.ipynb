{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu setting\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料準備\n",
    "* imageX : (.jpg), 讀取方式 : mpimg.imread()\n",
    "* LabelY : (int), 讀取方式 : pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels Y\n",
    "data = pd.read_csv('./certify_processed/labels.csv', encoding = 'big5')\n",
    "Y = data.iloc[0, 1:]\n",
    "\n",
    "# image X\n",
    "import matplotlib.image as mpimg\n",
    "img_dir = './certify_processed/images/'\n",
    "imgs = np.empty([3000, 12, 12])  # 存放圖片\n",
    "\n",
    "for img_index in range(3000):\n",
    "    # 讀取圖檔\n",
    "    img = mpimg.imread(img_dir+\"crop%04d.jpg\"%(img_index))\n",
    "    imgs[img_index]=img\n",
    "X = imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,\n",
    "                                                    Y[:3000],\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標準化\n",
    "* /255 (因為mping.imread讀進 0~255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "x_train /= 255.\n",
    "x_test /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400,), (600,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 12, 12), (600, 12, 12))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "* 變成一維陣列 (12x12=144)\n",
    "* 分成 10 類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 144)\n",
    "x_test = x_test.reshape(x_test.shape[0], 144)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 144), (600, 144))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型建置\n",
    "* 3 層 200 節點, 一層 10 sorftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               29000     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 111,410\n",
      "Trainable params: 111,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([Dense(200, input_dim=144),\n",
    "                    Activation('relu'),\n",
    "                    Dense(200),\n",
    "                    Activation('relu'),\n",
    "                    Dense(200),\n",
    "                    Activation('relu'),\n",
    "                    Dense(10),\n",
    "                    Activation('softmax'),\n",
    "                    ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples\n",
      "Epoch 1/10\n",
      "2400/2400 [==============================] - 1s 234us/sample - loss: 0.0413 - accuracy: 0.7854\n",
      "Epoch 2/10\n",
      "2400/2400 [==============================] - 0s 109us/sample - loss: 0.0021 - accuracy: 0.9987\n",
      "Epoch 3/10\n",
      "2400/2400 [==============================] - 0s 140us/sample - loss: 0.0010 - accuracy: 0.9987\n",
      "Epoch 4/10\n",
      "2400/2400 [==============================] - 0s 113us/sample - loss: 7.6811e-04 - accuracy: 0.9987\n",
      "Epoch 5/10\n",
      "2400/2400 [==============================] - 0s 111us/sample - loss: 6.3925e-04 - accuracy: 0.9987\n",
      "Epoch 6/10\n",
      "2400/2400 [==============================] - 0s 111us/sample - loss: 5.6752e-04 - accuracy: 0.9987\n",
      "Epoch 7/10\n",
      "2400/2400 [==============================] - 0s 119us/sample - loss: 5.1391e-04 - accuracy: 0.9987\n",
      "Epoch 8/10\n",
      "2400/2400 [==============================] - 0s 127us/sample - loss: 4.7638e-04 - accuracy: 0.9987\n",
      "Epoch 9/10\n",
      "2400/2400 [==============================] - 0s 121us/sample - loss: 4.4287e-04 - accuracy: 0.9987\n",
      "Epoch 10/10\n",
      "2400/2400 [==============================] - 0s 125us/sample - loss: 4.2648e-04 - accuracy: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23d67284eb8>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting\n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.5), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 123us/sample - loss: 2.0746e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00020746123077818387, 1.0]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing data\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameter of model\n",
    "model_json = model.to_json()\n",
    "open('Certiy_Recognize.json', 'w').write(model_json)\n",
    "model.save('Certiy_Recognize.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 剩下 1000 筆\n",
    "* unknown_img : (.jpg) 讀取方式 : mpimg.imread\n",
    "* reshape : 需要轉換 144\n",
    "* 亂數看結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_imgs = np.empty([1000, 12, 12])\n",
    "\n",
    "for img_index in range(3000, 4000, 1):\n",
    "    # 讀取圖檔\n",
    "    img = mpimg.imread(img_dir+\"crop%04d.jpg\"%(img_index))\n",
    "    unknown_imgs[img_index-3000]=img\n",
    "\n",
    "unknown_imgs = unknown_imgs.reshape(1000, 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_classes(unknown_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_len = 10\n",
    "pick = np.random.randint(0,1000, column_len)\n",
    "\n",
    "for i in range(column_len):\n",
    "    plt.subplot(1,column_len,i+1)\n",
    "    plt.imshow(unknown_imgs[pick[i]].reshape(12, 12), cmap='Greys')\n",
    "    plt.title(predict[pick[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
